# Графическое ядро эмулятора T18FL3 (HU + Cluster)

## 1. Цели и ограничения

- **Цель:** описать, как должен работать графический слой эмулятора **над** QEMU:
  - точные параметры дисплеев;
  - архитектура рендеринга (OpenGL);
  - интеграция с Android Presentation API (второй дисплей);
  - модель «слоёв» для приборной панели (Cluster).
- **Важно:** на этом этапе **не трогаем QEMU**. Вся архитектура формулируется так, чтобы:
  - входы графического ядра — это просто потоки кадров/поверхностей от Android и QNX;
  - позже можно будет подключить реальные источники (QEMU VNC / framebuffer, Remote Desktop, скриншоты) без переписывания ядра.

---

## 2. Параметры дисплеев и координатные системы

### 2.1. Реальное ГУ T18FL3

Из `ЭМУЛЯТОР_ДВА_ДИСПЛЕЯ.md`:

- **Основной дисплей (HU, Android):**
  - Разрешение: **1920×720**
  - Плотность: **160 dpi**
  - Ориентация: горизонтальная (landscape)
- **Второй дисплей (Cluster, HDMI, QNX/Android Presentation):**
  - Разрешение: **1920×720**
  - Плотность: **213 dpi**
  - Тип: **HDMI**
  - Флаг: **`FLAG_PRESENTATION`**

Система видит второй дисплей примерно так:

```text
DisplayDeviceInfo{"Экран HDMI": uniqueId="local:1", 1920 x 720,
type HDMI, FLAG_PRESENTATION}
```

### 2.2. Нормализованная система координат

Для эмулятора вводим единый «дизайн‑формат»:

- **Базовое логическое разрешение для обоих дисплеев:** `1920×720`.
- Все координаты (x, y) внутри графического ядра живут в этой системе.
- Масштабирование до размеров окна на Mac/web:
  - масштаб по минимальному коэффициенту, чтобы сохранить **соотношение сторон** 1920:720;
  - чёрные поля по краям допускаются (letterbox/pillarbox) — критично сохранить геометрию.

Это позволяет:

- безболезненно совмещать HU и Cluster в одном окне;
- перекладывать данные с реального устройства (dumpsys / скриншоты) без перерасчёта логики.

---

## 3. OpenGL‑архитектура на хосте

### 3.1. Общий подход

Графическое ядро на хосте (macOS) строится вокруг **OpenGL 3.3 Core** (или OpenGL ES 3.0+ при переносе):

- Для каждого виртуального дисплея (HU и Cluster) создаётся:
  - отдельный **Framebuffer Object (FBO)**;
  - один или несколько **GL‑текстур**, куда кладутся кадры от гостевых систем.
- Общий host‑UI (SwiftUI / web) использует эти текстуры как «готовые картинки»:
  - SwiftUI: обёртка над `NSOpenGLView` / Metal‑слоем;
  - web‑UI: сейчас это просто `<img>` с PNG, но логика всё равно описывается как GL‑пайплайн, чтобы дизайн масштабировался на нативный UI.

### 3.2. Минимальный набор сущностей

Для каждого дисплея:

- `GLTexture` (2D, RGBA8 или sRGB):
  - размер строго `1920×720`;
  - содержимое — последний актуальный кадр.
- `DisplaySurface`:
  - ссылка на `GLTexture`;
  - матрица трансформации (масштабирование под окно, повороты в будущем);
  - настройки гаммы/яркости (hook для отладки).
- Рендер‑цикл:
  1. Графическое ядро принимает новый кадр от источника (см. раздел 4).
  2. Декодирует (если кадр сжат в PNG/JPEG/H.264) до сырых пикселей.
  3. Заливает в `glTexSubImage2D` соответствующей текстуры.
  4. При следующем отрисовывании окна отрисовывает прямоугольник 1920×720 с этой текстурой.

### 3.3. OpenGL‑шейдеры

Минимальный комплект:

- **Вершинный шейдер**:
  - вход: позиция прямоугольника в нормализованных координатах + UV координаты;
  - выход: UV в фрагментный шейдер.
- **Фрагментный шейдер**:
  - семплит одну или несколько текстур (для слоёв);
  - линейное смешивание с альфой;
  - опциональное гамма‑корректирование.

Условие: вся логика слоёв (см. раздел 5) реализуется в фрагментном шейдере как простая композиция нескольких текстур.

### 3.4. Частоты обновления

Рекомендуемые цели (для документации, не как жёсткое требование сейчас):

- HU:
  - целевое **30 FPS** (для реалистичного UI и навигации);
  - минимально — **15 FPS**.
- Cluster:
  - базовый QNX‑слой — **15–30 FPS**;
  - если источник тяжёлый (remote desktop), допускается **5–10 FPS**, но с плавной анимацией стрелок внутри самого QNX.

Графическое ядро не навязывает FPS, оно просто:

- принимает кадры;
- при каждом приходе обновляет текстуру;
- рендерит по запросу окна (vsync системы).

---

## 4. Интеграция с Android Presentation API

### 4.1. Модель на реальном устройстве / AVD

Из `ЭМУЛЯТОР_ДВА_ДИСПЛЕЯ.md` и документов по ЯндексДог:

- Второй дисплей создаётся через:
  - **Presentation API** (`android.app.Presentation`);
  - **VirtualDisplay** (`DisplayManager.createVirtualDisplay`).
- Реальный сценарий:
  1. Android видит основной дисплей (`Display.DEFAULT_DISPLAY`) и HDMI‑дисплей c флагом `FLAG_PRESENTATION`.
  2. Приложение вызывает `DisplayManager.getDisplays()`, находит нужный `Display` (не id 0, с `FLAG_PRESENTATION`).
  3. Создаёт `Presentation`, рендерит туда упрощённую карту/индикацию для приборной панели.

```java
DisplayManager displayManager = (DisplayManager) getSystemService(Context.DISPLAY_SERVICE);
Display[] displays = displayManager.getDisplays();

Display secondaryDisplay = null;
for (Display display : displays) {
    if (display.getDisplayId() != Display.DEFAULT_DISPLAY &&
        (display.getFlags() & Display.FLAG_PRESENTATION) != 0) {
        secondaryDisplay = display;
        break;
    }
}

if (secondaryDisplay != null) {
    Presentation p = new Presentation(this, secondaryDisplay);
    p.setContentView(R.layout.presentation_layout);
    p.show();
}
```

### 4.2. Ожидаемая архитектура в эмуляторе

Графическое ядро эмулятора должно рассматривать Android Presentation как **отдельный источник кадров** для Cluster:

- Источники для Cluster:
  1. **QNX‑кластер** (основная приборка, стрелки, индикаторы).
  2. **Android Presentation** (мини‑карта, подсказки навигации).
  3. (опционально) **Host‑debug overlay** (оверлей от самого эмулятора).

Важное правило: для графического ядра **не важно**, как именно получены эти кадры:

- от реального устройства через `adb` + Remote Desktop;
- от QEMU через VNC;
- из AVD через `screencap`/stream.

Оно получает просто **набор текстур/буферов** и умеет их правильно совместить.

---

## 5. Модель слоёв для Cluster

### 5.1. Слои

Для приборной панели определяем следующую модель слоёв:

1. **Layer 0 – QNX_BASE**
   - Полный кадр приборной панели от QNX (спидометр, тахометр, индикаторы).
   - Непрозрачный фон.
2. **Layer 1 – ANDROID_NAV_OVERLAY**
   - Кадр с Android Presentation (упрощённая карта, стрелка поворота).
   - Может иметь прозрачный фон, чтобы не затереть базовую приборку.
3. **Layer 2 – DEBUG_OVERLAY (host)**
   - Рисуется самим эмулятором:
     - сетка;
     - отладочная информация по CAN (скорость, rpm);
     - подсветка активных зон.
   - Используется только в режимах отладки.

### 5.2. Комбинирование слоёв в OpenGL

В фрагментном шейдере:

1. Всегда семплится `QNX_BASE` (если текстура есть, иначе фон).
2. Если доступен `ANDROID_NAV_OVERLAY`:
   - семплится текстура;
   - если `alpha > threshold`, смешивается поверх `QNX_BASE` по стандартной формуле:

   \[
   C_\text{out} = C_\text{base} \cdot (1 - \alpha) + C_\text{nav} \cdot \alpha
   \]

3. Если включён DEBUG_OVERLAY:
   - рисуются линии/текст с pre‑multiplied alpha поверх результата.

Логика прозрачности (например, маска для зоны в центре приборки, где показывается карта) должна определяться **на стороне Android/QNX** (правильный фон и альфа в Presentation), а не в эмуляторе. Эмулятор только честно композитит слои.

### 5.3. Управление слоями

Уровень настройки (для документации, потом можно вынести в UI):

- В Python‑core / графическом ядре есть структура конфигурации:

```text
cluster_layers:
  qnx_base: enabled = true
  android_nav_overlay: enabled = true
  debug_overlay: enabled = false
```

- Host‑UI (web/SwiftUI) может давать переключатели:
  - «Показать только QNX»
  - «Показать только Android Overlay»
  - «Включить режим отладки кластеров»

---

## 6. Интерфейс между Python‑core и графическим ядром

### 6.1. Абстракции источников кадров

В документации фиксируем **логический интерфейс**, не привязанный к конкретным библиотекам:

- `FrameSource`:
  - `id`: строка (`"HU_ANDROID"`, `"CLUSTER_QNX"`, `"CLUSTER_ANDROID_OVERLAY"`).
  - `get_next_frame() -> bytes | None` — сжатые данные кадра (PNG/JPEG/H.264, договоримся на PNG/JPEG для простоты).
- `DisplayChannel`:
  - `name`: `"HU"` или `"CLUSTER"`;
  - список привязанных `FrameSource` и их роли (`base`, `overlay`, `debug`).

Python‑core:

- предоставляет графическому ядру один или несколько `FrameSource`;
- сам решает, откуда брать данные:
  - qemu VNC;
  - remote desktop;
  - файлы/заглушки (как сейчас, boot‑картинки).

### 6.2. Транспорт до UI

Для документации закладываем два варианта:

1. **Нативный GUI (SwiftUI + OpenGL/Metal):**
   - Графическое ядро живёт в нативном процессе;
   - Python‑core общается с ним через:
     - Unix‑сокеты / named pipes;
     - или in‑process embedding (Python встраивается в Swift).
   - Передаём либо:
     - уже загруженные в GPU текстуры (если общее адресное пространство);
     - либо сжатые PNG‑фреймы и минимальную метадату (номер кадра, источник).

2. **Web‑UI (текущая реализация):**
   - Python‑core отдаёт `/display/*/frame` как PNG;
   - браузер обновляет `<img>` с нужным интервалом;
   - в будущем можно перейти на:
     - WebSocket + бинарные фреймы;
     - WebRTC/MediaSource, если нужен realtime‑видео.

Документация описывает именно **логическую** схему; конкретный транспорт можно менять, пока сохраняется инвариант: «HU и Cluster — это независимо обновляемые каналы кадров».

---

## 7. Работа с OpenGL на macOS (резюме настроек)

Чтобы при переходе к нативному GUI не придумывать заново:

- Минимальные требования:
  - OpenGL 3.3 Core Profile;
  - двойная буферизация;
  - включённый vsync (для избежания tearing).
- Настройки контекста:
  - цветовое пространство: sRGB framebuffer;
  - глубина и трафарет не обязательны (2D‑рендеринг);
  - мультисэмплинг не критичен (UI, а не 3D‑рендер).
- Управление ресурсами:
  - один GL‑контекст на приложение;
  - FBO на дисплей;
  - переиспользование текстур (не пересоздавать на каждый кадр).

---

## 8. Порядок внедрения (без лезания в QEMU)

1. **Задокументировать** (этот файл) параметры дисплеев, модель слоёв и OpenGL‑пайплайн — ✅.
2. **Стабилизировать API Python‑core → UI**:
   - `/display/hu/frame`, `/display/cluster/frame` — уже реализованы как заглушки;
   - дополнительно задокументировать возможные роли слоёв (`base`, `overlay`, `debug`).
3. **Расширить web‑UI**:
   - добавить простые переключатели слоёв (позже, когда будут реальные источники Android/QNX);
   - визуализировать FPS / latency для каждого дисплея.
4. **Только потом**:
   - подменить источники кадров с заглушек (boot‑картинки) на реальные:
     - сначала через Remote Desktop/adb;
     - затем через QEMU (VNC / framebuffer).

Таким образом, графическое ядро и его документация уже готовы **принимать реальные кадры**, но мы сознательно откладываем интеграцию с QEMU до отдельного этапа.

---

## 9. Подробный OpenGL render loop

### 9.1. Жизненный цикл графического ядра

Высокоуровневый цикл (аналогичен и для нативного GUI, и для headless‑рендера в текстуры):

1. **Инициализация**:
   - создаётся GL‑контекст (Core Profile 3.3);
   - создаются FBO и текстуры для `HU` и `CLUSTER`:
     - `huTex`, `clusterBaseTex`, `clusterOverlayTex`, `clusterDebugTex`;
   - компилируются шейдеры (см. раздел 10).
2. **Главный цикл**:
   - читаем новые кадры из источников (`FrameSource.get_next_frame()`):
     - если есть новый кадр — декодируем в RGBA и заливаем в нужную текстуру через `glTexSubImage2D`;
   - отрисовываем:
     1. биндим FBO `huFbo`, рисуем прямоугольник с `huTex`;
     2. биндим FBO `clusterFbo`, вызываем фрагментный шейдер, который:
        - семплит `clusterBaseTex` (QNX);
        - семплит `clusterOverlayTex` (Android Presentation, если включён);
        - дорисовывает `clusterDebugTex` / примитивы отладки.
   - если это нативное окно — вызываем `swapBuffers` (vsync);
   - если это headless‑режим для web‑UI — читаем FBO в `glReadPixels`, кодируем в PNG и отдаём Python‑core.
3. **Завершение**:
   - удаляем текстуры/FBO/шейдеры;
   - уничтожаем контекст.

### 9.2. Псевдокод цикла

Псевдокод без конкретных библиотек:

```text
init_gl():
  ctx = create_gl_context()
  huTex = create_texture(1920, 720)
  clusterBaseTex = create_texture(1920, 720)
  clusterOverlayTex = create_texture(1920, 720)
  clusterDebugTex = create_texture(1920, 720)  # опционально

  huFbo = create_fbo(huTex)
  clusterFbo = create_fbo(clusterBaseTex)  # целевой буфер

  program_hu = build_shader_program(quad_vs, simple_fs)
  program_cluster = build_shader_program(quad_vs, cluster_layers_fs)

loop():
  while running:
    # 1. Обновляем текстуры из источников кадров
    if hu_frame := hu_source.get_next_frame():
      rgba = decode_image(hu_frame)  # PNG/JPEG → RGBA
      glBindTexture(GL_TEXTURE_2D, huTex)
      glTexSubImage2D(..., rgba)

    if qnx_frame := cluster_qnx_source.get_next_frame():
      rgba = decode_image(qnx_frame)
      glBindTexture(GL_TEXTURE_2D, clusterBaseTex)
      glTexSubImage2D(..., rgba)

    if android_overlay_frame := cluster_android_source.get_next_frame():
      rgba = decode_image(android_overlay_frame)
      glBindTexture(GL_TEXTURE_2D, clusterOverlayTex)
      glTexSubImage2D(..., rgba)

    if debug_overlay_frame := debug_source.get_next_frame():
      rgba = decode_image(debug_overlay_frame)
      glBindTexture(GL_TEXTURE_2D, clusterDebugTex)
      glTexSubImage2D(..., rgba)

    # 2. Рендерим HU
    glBindFramebuffer(GL_FRAMEBUFFER, huFbo)
    glViewport(0, 0, 1920, 720)
    glUseProgram(program_hu)
    bind_fullscreen_quad()
    glBindTexture(GL_TEXTURE_2D, huTex)
    draw_fullscreen_quad()

    # 3. Рендерим Cluster с слоями
    glBindFramebuffer(GL_FRAMEBUFFER, clusterFbo)
    glViewport(0, 0, 1920, 720)
    glUseProgram(program_cluster)
    set_uniform("uHasOverlay", android_overlay_enabled)
    set_uniform("uHasDebug", debug_enabled)
    bind_fullscreen_quad()

    glActiveTexture(GL_TEXTURE0)
    glBindTexture(GL_TEXTURE_2D, clusterBaseTex)
    glActiveTexture(GL_TEXTURE1)
    glBindTexture(GL_TEXTURE_2D, clusterOverlayTex)
    glActiveTexture(GL_TEXTURE2)
    glBindTexture(GL_TEXTURE_2D, clusterDebugTex)

    draw_fullscreen_quad()

    # 4. Выводим в окно или читаем FBO в память
    if native_window_mode:
      blit_fbos_to_default_framebuffer()
      swap_buffers()
    else:
      hu_image = read_fbo_to_png(huFbo)
      cluster_image = read_fbo_to_png(clusterFbo)
      send_to_python_core(hu_image, cluster_image)
```

---

## 10. Псевдокод шейдеров и слоёв

### 10.1. Вершинный шейдер (общий для HU и Cluster)

Идея: один fullscreen‑quad, UV координаты от 0 до 1.

```text
// quad_vs
in vec2 aPos;   // [-1, 1] x [-1, 1]
in vec2 aTex;   // [0, 1] x [0, 1]

out vec2 vTex;

void main() {
  vTex = aTex;
  gl_Position = vec4(aPos, 0.0, 1.0);
}
```

### 10.2. Фрагментный шейдер для HU

Простой pass‑through:

```text
// simple_fs
in vec2 vTex;
out vec4 fragColor;

uniform sampler2D uTexture;

void main() {
  fragColor = texture(uTexture, vTex);
}
```

### 10.3. Фрагментный шейдер для Cluster со слоями

```text
// cluster_layers_fs
in vec2 vTex;
out vec4 fragColor;

uniform sampler2D uBase;       // QNX_BASE
uniform sampler2D uOverlay;    // ANDROID_NAV_OVERLAY
uniform sampler2D uDebug;      // DEBUG_OVERLAY

uniform bool uHasOverlay;
uniform bool uHasDebug;

vec4 blend(vec4 base, vec4 over) {
  float a = over.a;
  return vec4(
    base.rgb * (1.0 - a) + over.rgb * a,
    1.0
  );
}

void main() {
  vec4 baseColor = texture(uBase, vTex);
  vec4 color = baseColor;

  if (uHasOverlay) {
    vec4 overlayColor = texture(uOverlay, vTex);
    // Допускаем, что background в overlay прозрачен
    color = blend(color, overlayColor);
  }

  if (uHasDebug) {
    vec4 debugColor = texture(uDebug, vTex);
    color = blend(color, debugColor);
  }

  fragColor = color;
}
```

Если на практике удобнее держать debug‑слой как векторную отрисовку (линии, прямоугольники), можно вместо `uDebug` просто дописать рисование примитивов в этом же шейдере по параметрам (CAN‑данные, выделенные зоны и т.п.).

---

## 11. Детализация режима Presentation и Android‑слоёв

### 11.1. Архитектура на Android‑стороне

Цель: добиться предсказуемого, «слоёвого» вывода навигации на второй дисплей, чтобы эмулятор мог честно его подмешать в Cluster.

Компоненты:

- `MainActivity` (основной экран HU).
- `PresentationActivity` / `ClusterPresentation` (класс, наследующий `Presentation`):
  - создаётся только для `Display` с `FLAG_PRESENTATION`;
  - внутри layout максимально простой:
    - `FrameLayout root`;
    - внутри `MapView`/`SurfaceView`/`TextureView` с картой/стрелкой;
    - фон — **прозрачный** или отлично маскируемый (чёрный/альфа‑канал), чтобы не забивать всю приборку.
- `TiggoSecondaryRenderThread`:
  - управляет частотой обновления карты / анимацией стрелки;
  - желательно привязан к CAN‑данным (скорость, поворот, маршрут).

Пример логики создания Presentation (из уже существующих документов, оформлено как целевое):

```java
public class ClusterController {
    private final Context context;
    private Presentation current;

    public ClusterController(Context ctx) {
        this.context = ctx.getApplicationContext();
    }

    public void attachToSecondaryDisplay() {
        DisplayManager dm = (DisplayManager) context.getSystemService(Context.DISPLAY_SERVICE);
        for (Display display : dm.getDisplays()) {
            if (display.getDisplayId() == Display.DEFAULT_DISPLAY) continue;
            if ((display.getFlags() & Display.FLAG_PRESENTATION) == 0) continue;

            current = new ClusterPresentation(context, display);
            current.show();
            break;
        }
    }

    public void detach() {
        if (current != null) {
            current.dismiss();
            current = null;
        }
    }
}
```

Где `ClusterPresentation`:

- в `onCreate` надувает `R.layout.cluster_presentation`;
- внутри layout строго соблюдает safe‑зону (центр панели), где карта не перекрывает критичные элементы QNX.

### 11.2. Требования к прозрачности и геометрии

Чтобы модель слоёв работала:

- **Фон Presentation**:
  - желательно полупрозрачный/прозрачный (ARGB‑фон), чтобы QNX‑приборка просвечивала;
  - либо фон полностью чёрный, но карта и стрелка рисуются в ограниченной области (центр), а графическое ядро потом вырежет прямоугольник залива (более сложный путь, лучше прозрачность).
- **Координаты**:
  - Presentation рендерится в том же разрешении 1920×720;
  - все константы позиций (где находится карта) фиксируются в коде/ресурсах, чтобы эмулятор мог при необходимости подсветить те же области.

### 11.3. Получение кадров Presentation для эмулятора

На этом этапе **не реализуем код**, но фиксируем архитектурный путь:

1. На реальном устройстве или AVD:
   - запускается `PresentationActivity`/`ClusterPresentation`;
   - каждые N миллисекунд захватывается кадр Presentation:
     - либо через `PixelCopy` из `SurfaceView/TextureView`;
     - либо через `screencap` с фильтрацией по второму дисплею (если возможно).
2. Кадр отправляется на хост:
   - через существующий Remote Desktop протокол (`RemoteDesktopServer` / ReverseTunnel);
   - формат: PNG/JPEG, `1920×720`, ARGB, желательно с альфой.
3. Python‑core принимает эти кадры как отдельный `FrameSource`:
   - `id = "CLUSTER_ANDROID_OVERLAY"`;
   - кадры идут в `clusterOverlayTex` (слой `ANDROID_NAV_OVERLAY`).

Важно: даже если QEMU ещё не в деле, эта цепочка даёт нам **реальный Android‑overlay**, который можно смешивать поверх статической/записанной QNX‑приборки.

### 11.4. Несколько слоёв внутри Android Presentation

В перспективе можно сделать многоуровневую схему и в самом Android‑слое:

- **Слои внутри Presentation**:
  1. `BACKGROUND_MASK` — форма окна, совпадающая с вырезом в приборке.
  2. `MAP_LAYER` — плитки карты от ЯндексДог.
  3. `ROUTE_LAYER` — линия маршрута, подсветка текущей полосы.
  4. `HUD_LAYER` — стрелка поворота, дистанция, иконки.

Для эмулятора эти подслои не видны по отдельности — он получает уже собранную картинку. Но знание этой структуры:

- помогает правильно тестировать слои (например, отключать карту, оставляя только HUD, и смотреть как это выглядит в кластере);
- позволяет в будущем, при глубокой интеграции, имитировать отключение отдельных подслоёв в самом Android‑приложении для отладки.

---

## 12. Итог по текущему этапу (до QEMU)

На данном этапе у нас зафиксировано:

- **Параметры дисплеев** HU/Cluster и единая координатная система 1920×720.
- **OpenGL‑пайплайн**: текстуры, FBO, render loop, базовые шейдеры.
- **Модель слоёв Cluster**: QNX‑база, Android Presentation overlay, debug‑оверлей.
- **Интерфейс Python‑core ↔ графическое ядро**: абстрактные `FrameSource` и каналы `HU`/`CLUSTER`.
- **Режим Presentation**:
  - как Android‑приложение будет рисовать второй дисплей;
  - как мы будем получать эти кадры и накладывать их поверх QNX.

Следующий логичный шаг (отдельный этап) — уже не документация, а реализация:

1. Черновой OpenGL‑рендерер (можно начать с простого headless‑рендера в текстуры/PNG).
2. Инструменты на Android‑стороне для захвата кадров Presentation.
3. Простая линия связи «Presentation → Python‑core → web‑UI» без участия QEMU.



